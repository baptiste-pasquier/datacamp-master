{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Data\n",
    "\n",
    "Author: [Alexandre Gramfort](http://alexandre.gramfort.net)\n",
    "\n",
    "<img src=\"img/borat.png\" width=50%>\n",
    "\n",
    "Based on the work of [J.F. Puget](https://www.ibm.com/developerworks/community/blogs/jfp/entry/Tidy_Data_In_Python?lang=en)\n",
    "\n",
    "This lecture is based on the article from Hadley Wickham: [Tidy Data](http://vita.had.co.nz/papers/tidy-data.pdf).\n",
    "\n",
    "If you don't know Hadley Wickham see https://en.wikipedia.org/wiki/Hadley_Wickham\n",
    "\n",
    "Let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "It is often said that data scientists spend only 20% of their time analyzing their data, and 80% of time cleaning it. Indeed, maintaining a tidy, easy-to-use dataset is crucial for any data analysis especially if it's \"big data\".\n",
    "\n",
    "In the paper Tidy Data, Hadley Wickham gives **definitions of tidy and messy data** so that all data scientists can keep their work organized.\n",
    "\n",
    "In this lecture, you'll learn to transform messy datasets into tidy datasets using the pandas package in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need two Python packages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show readers which versions we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work = pd.DataFrame([[80.0, 20.0]], columns=[\"Data cleaning\", \"Machine Learning\"])\n",
    "\n",
    "work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work = work.T\n",
    "work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work.columns = [\"Work pct.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work[\"Work pct.\"].plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Data and Messy Data\n",
    "\n",
    "What exactly marks the difference between *tidy* data and *messy* data? It is not only how organized and intuitive the datasets look to our human eyes, but also how **easily and efficiently they can be processed by computers**.\n",
    "\n",
    "In his seminal paper [Tidy Data](https://www.jstatsoft.org/article/view/v059i10), Hadley Wickham proposed three standards for tidy data:\n",
    "\n",
    "1. Each variable forms a **column**\n",
    "2. Each observation forms a **row**\n",
    "3. Each type of observation forms a **unit**.\n",
    "\n",
    "Here, we'll focus on the first two rules and show you how we can use the Python package [pandas](http://pandas.pydata.org/) to deal with datasets violating them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Let's get started, with a dataframe called `messy`.\n",
    "\n",
    "This dataset, which appears in Wickham's paper, shows the number of people who choose either of two treatments in a hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy = pd.DataFrame(\n",
    "    {\n",
    "        \"First\": [\"John\", \"Jane\", \"Mary\"],\n",
    "        \"Last\": [\"Smith\", \"Doe\", \"Johnson\"],\n",
    "        \"Treatment A\": [np.nan, 16, 3],\n",
    "        \"Treatment B\": [2, 11, 1],\n",
    "    }\n",
    ")\n",
    "messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe its structure in comparison with Wickham's rules.\n",
    "\n",
    "This dataset is *messy* because it violates rule #2: it combines Treatment A and Treatment B, two distinct observations, in a single row.\n",
    "\n",
    "**Messy data sets exist because they are often convenient for showing them to human** as they are compact.\n",
    "This explains why this form is often used in publications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People may prefer the transpose view of that data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Messy data sets are not that easy to process by statistical or machine learning packages.**\n",
    "\n",
    "These often assume that examples are provided as rows in a 2d array whose columns are features. This is precisely what a tidy data set is.\n",
    "\n",
    "Applying the `melt()` function to it creates a tidy version of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.melt(messy, id_vars=[\"First\", \"Last\"])\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are fine but column names aren't really meaningful.  Fortinately, the `melt()` function has arguments for renaming them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.melt(\n",
    "    messy, id_vars=[\"First\", \"Last\"], var_name=\"treatment\", value_name=\"result\"\n",
    ")\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple(r) melt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy = pd.DataFrame(\n",
    "    {\"row\": [\"A\", \"B\", \"C\"], \"a\": [1, 2, 3], \"b\": [4, 5, 6], \"c\": [7, 8, 9]}\n",
    ")\n",
    "messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(messy, id_vars=\"row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.melt(messy, id_vars=\"row\", var_name=\"dimension\", value_name=\"length\")\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot is almost the inverse of melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy1 = tidy.pivot(index=\"row\", columns=\"dimension\", values=\"length\")\n",
    "messy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is almost the same as the orginal dataframe, except that row is used as index.  We can move it back to a row easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy1.reset_index(inplace=True)\n",
    "messy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to remove the name for the set of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy1.columns.name = \"\"\n",
    "messy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the original dataframe, up to column reordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column headers are values, not variable names\n",
    "\n",
    "This is the first issue with messy data in Hadley's paper.  Let's first create the dataframe used as an example.\n",
    "\n",
    "For practical reasons, it was simpler to first construct the transpose of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy = pd.DataFrame(\n",
    "    {\n",
    "        \"Agnostic\": [27, 34, 60, 81, 76, 137],\n",
    "        \"Atheist\": [12, 27, 37, 52, 35, 70],\n",
    "        \"Buddhist\": [27, 21, 30, 34, 33, 58],\n",
    "        \"Catholic\": [418, 617, 732, 670, 638, 1116],\n",
    "        \"Don't know/refused\": [15, 14, 15, 11, 10, 35],\n",
    "        \"Evangelical Prot\": [575, 869, 1064, 982, 881, 1486],\n",
    "        \"Hindu\": [1, 9, 7, 9, 11, 34],\n",
    "        \"Historically Black Prot\": [228, 244, 236, 238, 197, 223],\n",
    "        \"Jehovah's Witness\": [20, 27, 24, 24, 21, 30],\n",
    "        \"Jewish\": [19, 19, 25, 25, 30, 95],\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def transpose(df, columns):\n",
    "    df = df.T.copy()\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = columns\n",
    "    return df\n",
    "\n",
    "\n",
    "messy = transpose(\n",
    "    messy, [\"religion\", \"<$10k\", \"$10-20k\", \"$20-30k\", \"$30-40k\", \"$40-50k\", \"$50-75k\"]\n",
    ")\n",
    "\n",
    "messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION</b>:\n",
    "     <ul>\n",
    "      <li>Why is the dataset messy?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the `melt()` function is our friend.  We sort the result by religion to make it easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = pd.melt(messy, id_vars=[\"religion\"], var_name=\"income\", value_name=\"freq\")\n",
    "tidy.sort_values(by=[\"religion\"], inplace=True)\n",
    "tidy.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy.groupby(\"religion\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables are stored in both rows and columns\n",
    "\n",
    "This example is a little trickier. This dataset comes from the World Health Organisation, and records the counts of confirmed tuberculosis (TB) cases by country, year, and demographic group.  We first read the input data as a data frame.\n",
    "\n",
    "This data is available at https://github.com/hadley/tidy-data/blob/master/data/tb.csv\n",
    "\n",
    "Reading it is easy. We remove the `new_sp_` prefix appearing in most columns, and we rename a couple of columns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/hadley/tidy-data/master/data/tb.csv\"\n",
    "tb = pd.read_csv(url)\n",
    "tb.columns = tb.columns.str.replace(\"new_sp_\", \"\")\n",
    "tb.rename(columns={\"new_sp\": \"total\", \"iso2\": \"country\"}, inplace=True)\n",
    "tb.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use year 2000, and drop few columns, to stay in sync with Wickham's article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy = tb[tb[\"year\"] == 2000].copy()\n",
    "messy.drop([\"total\", \"m04\", \"m514\", \"f04\", \"f514\"], axis=1, inplace=True)\n",
    "messy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy.iloc[:, :11].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `melt()` function is useful, but is not enough.  Let's use it still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molten = pd.melt(messy, id_vars=[\"country\", \"year\"], value_name=\"cases\")\n",
    "molten.sort_values(by=[\"year\", \"country\"], inplace=True)\n",
    "molten.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molten[\"variable\"].str.startswith(\"m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION</b>:\n",
    "     <ul>\n",
    "      <li>What is still the problem?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What isn't really nice is the encoding of sex and age ranges as a string in the `variable` column.\n",
    "\n",
    "Let's process the dataset to create two additional columns, one for the sex, and one for the age range.\n",
    "\n",
    "We then remove the `variable` column.\n",
    "\n",
    "The tidy form also makes it easy to remove the values where the age is `u`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_age(s):\n",
    "    s = s[1:]\n",
    "    if s == \"65\":\n",
    "        return \"65+\"\n",
    "    else:\n",
    "        return s[:-2] + \"-\" + s[-2:]\n",
    "\n",
    "\n",
    "tidy = molten[molten[\"variable\"] != \"mu\"].copy()\n",
    "tidy[\"sex\"] = tidy[\"variable\"].apply(lambda s: s[:1])\n",
    "tidy[\"age\"] = tidy[\"variable\"].apply(parse_age)\n",
    "tidy = tidy[[\"country\", \"year\", \"sex\", \"age\", \"cases\"]]\n",
    "tidy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy.groupby(\"country\").sum().sort_values(by=\"cases\", ascending=False)[\"cases\"].head(\n",
    "    10\n",
    ").plot(kind=\"pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables are stored in both rows and columns (tricky)\n",
    "\n",
    "The most **complicated form of messy data occurs when variables are stored in both rows and\n",
    "columns**. We consider here daily weather data from the Global Historical Climatology Network\n",
    "for one weather station (MX17004) in Mexico for five months in 2010. It has variables in\n",
    "individual columns (id, year, month), spread across columns (day, d1–d31) and across rows\n",
    "(tmin, tmax) (minimum and maximum temperature). Months with less than 31 days have\n",
    "structural missing values for the last day(s) of the month. The element column is not a\n",
    "variable; it stores the names of variables.\n",
    "\n",
    "We'll only consider columns from d1 to d8 to save space.\n",
    "\n",
    "Let's first create the dataframe.  This time, I create it using an array instead of a dictionary, just for the fun of doing something a bit different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"id\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"element\",\n",
    "    \"d1\",\n",
    "    \"d2\",\n",
    "    \"d3\",\n",
    "    \"d4\",\n",
    "    \"d5\",\n",
    "    \"d6\",\n",
    "    \"d7\",\n",
    "    \"d8\",\n",
    "]\n",
    "data = [\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        1,\n",
    "        \"tmax\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        1,\n",
    "        \"tmin\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        2,\n",
    "        \"tmax\",\n",
    "        np.nan,\n",
    "        27.3,\n",
    "        24.1,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        2,\n",
    "        \"tmin\",\n",
    "        np.nan,\n",
    "        14.4,\n",
    "        14.4,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        3,\n",
    "        \"tmax\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        32.1,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        3,\n",
    "        \"tmin\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        14.2,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        4,\n",
    "        \"tmax\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        4,\n",
    "        \"tmin\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        5,\n",
    "        \"tmax\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "    [\n",
    "        \"MX17004\",\n",
    "        2010,\n",
    "        5,\n",
    "        \"tmin\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "    ],\n",
    "]\n",
    "messy = pd.DataFrame(data=data, columns=columns)\n",
    "messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the values are not relevant.  However, filtering the NaN values is imposible here.  We need to melt the dataframe first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molten = pd.melt(\n",
    "    messy,\n",
    "    id_vars=[\n",
    "        \"id\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"element\",\n",
    "    ],\n",
    "    var_name=\"day\",\n",
    ")\n",
    "molten.dropna(inplace=True)\n",
    "molten = molten.reset_index(drop=True)\n",
    "molten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe is not in tidy form yet.  First, the column `element` contains variable names.  Second, the columns `year, month, day` represent one variable: the date.  Let's fix the latter problem first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    return \"%d-%02d-%02d\" % (row[\"year\"], row[\"month\"], int(row[\"day\"][1:]))\n",
    "\n",
    "\n",
    "molten[\"date\"] = molten.apply(f, axis=1)\n",
    "molten = molten[[\"id\", \"element\", \"value\", \"date\"]].copy()\n",
    "molten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molten[\"date\"] = pd.to_datetime(molten[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molten.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to pivot the element column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = molten.pivot(index=\"date\", columns=\"element\", values=\"value\")\n",
    "tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a minute.  \n",
    "\n",
    "Where is the id?\n",
    "\n",
    "One way to keep it, is to move the id to an index with the `groupby()` function, and apply `pivot()` inside each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy = molten.groupby(\"id\").apply(\n",
    "    pd.DataFrame.pivot, index=\"date\", columns=\"element\", values=\"value\"\n",
    ")\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost there.  We simply have to move id back as a column with the `reset_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy.reset_index(inplace=True)\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get rid of the `element` name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy.columns.name = \"\"\n",
    "tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et Voilà!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple types in one table\n",
    "\n",
    "This example is used to illustrate two of the above problems.  \n",
    "\n",
    "Let's create it. It is an excerpt from the Billboard top hits for 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"year\",\n",
    "    \"artist\",\n",
    "    \"track\",\n",
    "    \"time\",\n",
    "    \"date entered\",\n",
    "    \"wk1\",\n",
    "    \"wk2\",\n",
    "    \"wk3\",\n",
    "]\n",
    "\n",
    "data = [\n",
    "    [\n",
    "        2000,\n",
    "        \"2,Pac\",\n",
    "        \"Baby Don't Cry\",\n",
    "        \"4:22\",\n",
    "        \"2000-02-26\",\n",
    "        87,\n",
    "        82,\n",
    "        72,\n",
    "    ],\n",
    "    [\n",
    "        2000,\n",
    "        \"2Ge+her\",\n",
    "        \"The Hardest Part Of ...\",\n",
    "        \"3:15\",\n",
    "        \"2000-09-02\",\n",
    "        91,\n",
    "        87,\n",
    "        92,\n",
    "    ],\n",
    "    [\n",
    "        2000,\n",
    "        \"3 Doors Down\",\n",
    "        \"Kryptonite\",\n",
    "        \"3:53\",\n",
    "        \"2000-04-08\",\n",
    "        81,\n",
    "        70,\n",
    "        68,\n",
    "    ],\n",
    "    [\n",
    "        2000,\n",
    "        \"98^0\",\n",
    "        \"Give Me Just One Nig...\",\n",
    "        \"3:24\",\n",
    "        \"2000-08-19\",\n",
    "        51,\n",
    "        39,\n",
    "        34,\n",
    "    ],\n",
    "    [\n",
    "        2000,\n",
    "        \"A*Teens\",\n",
    "        \"Dancing Queen\",\n",
    "        \"3:44\",\n",
    "        \"2000-07-08\",\n",
    "        97,\n",
    "        97,\n",
    "        96,\n",
    "    ],\n",
    "    [\n",
    "        2000,\n",
    "        \"Aaliyah\",\n",
    "        \"I Don't Wanna\",\n",
    "        \"4:15\",\n",
    "        \"2000-01-29\",\n",
    "        84,\n",
    "        62,\n",
    "        51,\n",
    "    ],\n",
    "    [\n",
    "        2000,\n",
    "        \"Aaliyah\",\n",
    "        \"Try Again\",\n",
    "        \"4:03\",\n",
    "        \"2000-03-18\",\n",
    "        59,\n",
    "        53,\n",
    "        38,\n",
    "    ],\n",
    "    [2000, \"Adams,Yolanda\", \"Open My Heart\", \"5:30\", \"2000-08-26\", 76, 76, 74],\n",
    "]\n",
    "\n",
    "messy = pd.DataFrame(data=data, columns=columns)\n",
    "messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is messy because there are several observations per row, in the columns wk1, wk2, wk3.\n",
    "\n",
    "We can get one observation per row by metling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molten = pd.melt(\n",
    "    messy,\n",
    "    id_vars=[\"year\", \"artist\", \"track\", \"time\", \"date entered\"],\n",
    "    var_name=\"week\",\n",
    "    value_name=\"rank\",\n",
    ")\n",
    "molten.sort_values(by=[\"date entered\", \"week\"], inplace=True)\n",
    "molten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clean the dataset further, first by turning week into number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molten[\"week\"] = molten[\"week\"].apply(lambda s: int(s[2:]))\n",
    "molten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need the starting date of the week for each observation, instead of the date the track entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def increment_date(row):\n",
    "    date = datetime.strptime(row[\"date entered\"], \"%Y-%m-%d\")\n",
    "    return date + timedelta(7) * (row[\"week\"] - 1)\n",
    "\n",
    "\n",
    "molten[\"date\"] = molten.apply(increment_date, axis=1)\n",
    "molten.drop(\"date entered\", axis=1, inplace=True)\n",
    "molten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, this dataset is **denormalized**.\n",
    "\n",
    "This is fine for most statistical and machine learning packages, but we might want to normalize it, for example to be stored in an SQL database.\n",
    "\n",
    "It means that we should **group information that is repeated every week** for a track in a separate table.\n",
    "\n",
    "This information appears in columns `year ,artist, track, time`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_track = (\n",
    "    molten[[\"year\", \"artist\", \"track\", \"time\"]]\n",
    "    .groupby([\"year\", \"artist\", \"track\"])\n",
    "    .first()\n",
    ")\n",
    "tidy_track.reset_index(inplace=True)\n",
    "tidy_track.reset_index(inplace=True)\n",
    "tidy_track.rename(columns={\"index\": \"id\"}, inplace=True)\n",
    "tidy_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_rank = pd.merge(molten, tidy_track, on=\"track\")\n",
    "tidy_rank = tidy_rank[[\"id\", \"date\", \"rank\"]]\n",
    "tidy_rank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The end\n",
    "\n",
    "Making your data tidy will take you a lot of time. Keep it mind that there is\n",
    "not always a single way of tidying data. It can dependent of the question\n",
    "to specify what is an observation, a sample, and what is a feature, a variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "navigate_menu": false,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
